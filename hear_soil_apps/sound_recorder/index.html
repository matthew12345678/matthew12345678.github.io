<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Mic Recorder</title>

<style>
body {
    background: linear-gradient(135deg, #0057b8, #003c7a);
    color: #ffdd00;
    font-family: Arial, sans-serif;
    text-align: center;
    padding: 40px;
}

h1 {
    font-size: 32px;
    margin-bottom: 30px;
}

button {
    padding: 14px 28px;
    margin: 12px;
    font-size: 18px;
    border: none;
    border-radius: 8px;
    cursor: pointer;
    font-weight: bold;
    transition: 0.2s ease;
}

button:hover {
    transform: scale(1.05);
}

#record {
    background: #ffdd00;
    color: #003c7a;
}

#stop {
    background: #002855;
    color: #ffdd00;
}

#meterContainer {
    width: 500px;
    height: 22px;
    background: #002855;
    margin: 30px auto;
    border-radius: 12px;
    overflow: hidden;
    border: 2px solid #ffdd00;
}

#meter {
    height: 100%;
    width: 0%;
    background: #ffdd00;
}

canvas {
    background: #002855;
    border-radius: 10px;
    margin-top: 20px;
    border: 2px solid #ffdd00;
}
</style>
</head>

<body>

<h1>ðŸŽ¤ Microphone Recorder</h1>

<button id="record">Start Recording</button>
<button id="stop" disabled>Stop</button>

<div id="meterContainer">
    <div id="meter"></div>
</div>

<canvas id="waveform" width="700" height="180"></canvas>

<script>

let audioContext;
let analyser;
let mediaRecorder;
let audioChunks = [];
let animationId;
let micStream;

const recordBtn = document.getElementById("record");
const stopBtn = document.getElementById("stop");
const meter = document.getElementById("meter");
const canvas = document.getElementById("waveform");
const ctx = canvas.getContext("2d");

async function startRecording() {

    micStream = await navigator.mediaDevices.getUserMedia({ audio: true });

    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const source = audioContext.createMediaStreamSource(micStream);

    analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    source.connect(analyser);

    mediaRecorder = new MediaRecorder(micStream);
    audioChunks = [];

    mediaRecorder.ondataavailable = e => {
        if (e.data.size > 0) audioChunks.push(e.data);
    };

    mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks);
        const wavBlob = await convertToWav(blob);
        downloadBlob(wavBlob, "recording.wav");
        micStream.getTracks().forEach(track => track.stop());
    };

    mediaRecorder.start();
    draw();
    recordBtn.disabled = true;
    stopBtn.disabled = false;
}

recordBtn.onclick = startRecording;

stopBtn.onclick = () => {
    mediaRecorder.stop();
    cancelAnimationFrame(animationId);
    meter.style.width = "0%";
    recordBtn.disabled = false;
    stopBtn.disabled = true;
};

function draw() {

    const bufferLength = analyser.fftSize;
    const dataArray = new Uint8Array(bufferLength);

    function animate() {

        analyser.getByteTimeDomainData(dataArray);

        ctx.fillStyle = "#002855";
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        ctx.lineWidth = 2;
        ctx.strokeStyle = "#ffdd00";
        ctx.beginPath();

        const sliceWidth = canvas.width / bufferLength;
        let x = 0;
        let sum = 0;

        for (let i = 0; i < bufferLength; i++) {
            const v = dataArray[i] / 128.0;
            const y = v * canvas.height / 2;

            if (i === 0) ctx.moveTo(x, y);
            else ctx.lineTo(x, y);

            x += sliceWidth;
            sum += Math.abs(dataArray[i] - 128);
        }

        ctx.stroke();

        const rms = sum / bufferLength;
        const level = Math.min((rms / 50) * 100, 100);
        meter.style.width = level + "%";

        animationId = requestAnimationFrame(animate);
    }

    animate();
}

async function convertToWav(blob) {
    const arrayBuffer = await blob.arrayBuffer();
    const ctx = new (window.AudioContext || window.webkitAudioContext)();
    const decoded = await ctx.decodeAudioData(arrayBuffer.slice(0));
    const wav = audioBufferToWav(decoded);
    return new Blob([wav], { type: "audio/wav" });
}

function audioBufferToWav(buffer) {
    const length = buffer.length;
    const channels = buffer.numberOfChannels;
    const sampleRate = buffer.sampleRate;
    const bytesPerSample = 2;
    const blockAlign = channels * bytesPerSample;

    const bufferOut = new ArrayBuffer(44 + length * channels * bytesPerSample);
    const view = new DataView(bufferOut);

    const writeString = (offset, string) => {
        for (let i = 0; i < string.length; i++)
            view.setUint8(offset + i, string.charCodeAt(i));
    };

    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * channels * bytesPerSample, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, channels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * blockAlign, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, length * channels * bytesPerSample, true);

    let offset = 44;

    for (let i = 0; i < length; i++) {
        for (let channel = 0; channel < channels; channel++) {
            let sample = buffer.getChannelData(channel)[i];
            sample = Math.max(-1, Math.min(1, sample));
            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
            offset += 2;
        }
    }

    return bufferOut;
}

function downloadBlob(blob, filename) {
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = filename;
    a.click();
    URL.revokeObjectURL(url);
}

</script>

</body>
</html>
